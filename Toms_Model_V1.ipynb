{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: Too many arguments.\n",
      "\n",
      "usage: git clone [<options>] [--] <repo> [<dir>]\n",
      "\n",
      "    -v, --verbose         be more verbose\n",
      "    -q, --quiet           be more quiet\n",
      "    --progress            force progress reporting\n",
      "    --reject-shallow      don't clone shallow repository\n",
      "    -n, --no-checkout     don't create a checkout\n",
      "    --bare                create a bare repository\n",
      "    --mirror              create a mirror repository (implies bare)\n",
      "    -l, --local           to clone from a local repository\n",
      "    --no-hardlinks        don't use local hardlinks, always copy\n",
      "    -s, --shared          setup as shared repository\n",
      "    --recurse-submodules[=<pathspec>]\n",
      "                          initialize submodules in the clone\n",
      "    --recursive ...       alias of --recurse-submodules\n",
      "    -j, --jobs <n>        number of submodules cloned in parallel\n",
      "    --template <template-directory>\n",
      "                          directory from which templates will be used\n",
      "    --reference <repo>    reference repository\n",
      "    --reference-if-able <repo>\n",
      "                          reference repository\n",
      "    --dissociate          use --reference only while cloning\n",
      "    -o, --origin <name>   use <name> instead of 'origin' to track upstream\n",
      "    -b, --branch <branch>\n",
      "                          checkout <branch> instead of the remote's HEAD\n",
      "    -u, --upload-pack <path>\n",
      "                          path to git-upload-pack on the remote\n",
      "    --depth <depth>       create a shallow clone of that depth\n",
      "    --shallow-since <time>\n",
      "                          create a shallow clone since a specific time\n",
      "    --shallow-exclude <revision>\n",
      "                          deepen history of shallow clone, excluding rev\n",
      "    --single-branch       clone only one branch, HEAD or --branch\n",
      "    --no-tags             don't clone any tags, and make later fetches not to follow them\n",
      "    --shallow-submodules  any cloned submodules will be shallow\n",
      "    --separate-git-dir <gitdir>\n",
      "                          separate git dir from working tree\n",
      "    -c, --config <key=value>\n",
      "                          set config inside the new repository\n",
      "    --server-option <server-specific>\n",
      "                          option to transmit\n",
      "    -4, --ipv4            use IPv4 addresses only\n",
      "    -6, --ipv6            use IPv6 addresses only\n",
      "    --filter <args>       object filtering\n",
      "    --remote-submodules   any cloned submodules will use their remote-tracking branch\n",
      "    --sparse              initialize sparse-checkout file to include only files at root\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# INIT\n",
    "!git clone -q https: // github.com/AlpaslanErdag/cardata\n",
    "import random\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dropout, Flatten, Dense, Conv2D\n",
    "import glob\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from imgaug import augmenters as iaa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.optimizers import Adam, SGD  # - Works\n",
    "from keras.models import Sequential\n",
    "import keras\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import imutils\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "def load_img_steering(datadir, df):\n",
    "    image_path = []\n",
    "    angle = []\n",
    "    for i in range(len(data)):\n",
    "        indexed_data = data.iloc[i]\n",
    "        image_id = indexed_data[0]\n",
    "        image_path.append(os.path.join(datadir, image_id))\n",
    "        angle.append(float(indexed_data[1]))\n",
    "    image_paths = np.asarray(image_path)\n",
    "    angles = np.asarray(angle)\n",
    "    image_ids = np.asarray(image_id)\n",
    "    return image_paths, angles\n",
    "\n",
    "\n",
    "def load_speed_img(datadir, df):\n",
    "    image_path1 = []\n",
    "    speed1 = []\n",
    "    for i in range(len(data)):\n",
    "        indexed_data = data.iloc[i]\n",
    "        image_id = indexed_data[0]\n",
    "        image_path1.append(os.path.join(datadir, image_id))\n",
    "        speed1.append((indexed_data[2]))\n",
    "    image_paths1 = np.asarray(image_path1)\n",
    "    speeds1 = np.asarray(speed1)\n",
    "    return image_paths1, speeds1\n",
    "\n",
    "\n",
    "def load_test_img(datadir, df):\n",
    "    test_path = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        indexed_data = data.iloc[i]\n",
    "        image_id = indexed_data[0]\n",
    "        test_path.append(os.path.join(datadir, image_id))\n",
    "        test_paths = np.asarray(test_path)\n",
    "\n",
    "    return test_paths\n",
    "\n",
    "\n",
    "def zoom(image):\n",
    "    zoom = iaa.Affine(scale=(1, 1.3))\n",
    "    image = zoom.augment_image(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "def pan(image):\n",
    "    pan = iaa.Affine(translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)})\n",
    "    image = pan.augment_image(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "def img_random_brightness(image):\n",
    "    brightness = iaa.Multiply((0.4, 1.2))\n",
    "    image = brightness.augment_image(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "def img_random_flip(image, angle):\n",
    "    image = cv2.flip(image, 1)\n",
    "    angle = 1 - angle\n",
    "    return image, angle\n",
    "\n",
    "\n",
    "def blur(image):\n",
    "    kernel_size = random.randint(\n",
    "        1, 5)  # kernel larger than 5 would make the image way too blurry\n",
    "    image = cv2.blur(image, (kernel_size, kernel_size))\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def random_augment(image, steering_angle):\n",
    "    image = mpimg.imread(image)\n",
    "    if np.random.rand() < 0.5:\n",
    "        image = pan(image)\n",
    "    if np.random.rand() < 0.5:\n",
    "        image = zoom(image)\n",
    "    if np.random.rand() < 0.5:\n",
    "        image = blur(image)\n",
    "    if np.random.rand() < 0.5:\n",
    "        image = img_random_brightness(image)\n",
    "    if np.random.rand() < 0.5:\n",
    "        image, steering_angle = img_random_flip(image, steering_angle)\n",
    "\n",
    "    return image, steering_angle\n",
    "\n",
    "\n",
    "def angle_preprocess(img):\n",
    "    #img = img[50:,:,:]\n",
    "    img = img[int(img.shape[0] / 2):, :, :]\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "    img = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "    #img = cv2.resize(img, (200, 66))\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    img = cv2.Canny(img, 100, 200)\n",
    "    img = cv2.merge((img, img, img))\n",
    "    img = cv2.resize(img, (200, 66))\n",
    "    #img = img / 255.0\n",
    "    #img = np.true_divide(image, 255, dtype=np.float32,casting=\"unsafe\")\n",
    "    return img\n",
    "\n",
    "\n",
    "def speed_preprocess(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "    image = cv2.resize(image, (200, 66))\n",
    "    # hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    # lower = np.array([0, 164, 0])\n",
    "    # upper = np.array([179, 255, 255])\n",
    "    # mask = cv2.inRange(hsv, lower, upper)\n",
    "    # image = cv2.bitwise_and(image, image, mask = mask)\n",
    "    #image = image[int(image.shape[0] / 4):, :, :]\n",
    "    return image\n",
    "\n",
    "\n",
    "def angle_batch_generator(image_paths, steering_ang, batch_size, istraining):\n",
    "\n",
    "    while True:\n",
    "        batch_img = []\n",
    "        batch_steering = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            random_index = random.randint(\n",
    "                0,\n",
    "                len(image_paths) - 1\n",
    "            )  # Picks random image in the dataset, creating a random batch of size batch_size\n",
    "\n",
    "            if istraining:\n",
    "                im, steering = random_augment(\n",
    "                    image_paths[random_index], steering_ang[random_index]\n",
    "                )  # If training data, augment the image\n",
    "\n",
    "            else:\n",
    "                im = mpimg.imread(\n",
    "                    image_paths[random_index])  # If not, just load image\n",
    "                steering = steering_ang[random_index]\n",
    "\n",
    "            im = angle_preprocess(im)  # Pass image through pipeline\n",
    "            batch_img.append(im)\n",
    "            batch_steering.append(steering)\n",
    "        yield (np.asarray(batch_img), np.asarray(batch_steering)\n",
    "               )  # Returns generator/ lazy iterator\n",
    "\n",
    "\n",
    "def speed_batch_generator(image_paths, steering_ang, batch_size, istraining):\n",
    "\n",
    "    while True:\n",
    "        batch_img = []\n",
    "        batch_steering = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            random_index = random.randint(\n",
    "                0,\n",
    "                len(image_paths) - 1\n",
    "            )  # Picks random image in the dataset, creating a random batch of size batch_size\n",
    "\n",
    "            if istraining:\n",
    "                im = mpimg.imread(image_paths[random_index])  # Add image to dataset\n",
    "                steering = steering_ang[random_index]\n",
    "\n",
    "                im, steering = random_augment(image_paths[random_index], steering_ang[random_index])\n",
    "\n",
    "                # Also augment the data and add to the dataset. Can loop here to increase dataset size\n",
    "                # for i in range(3):\n",
    "                #     im_aug, steering_aug = random_augment(image_paths[random_index], steering_ang[random_index])  \n",
    "                #     im_aug = speed_preprocess(im_aug)\n",
    "                #     batch_img.append(im_aug)\n",
    "                #     batch_steering.append(steering_aug)\n",
    "\n",
    "            else:\n",
    "                im = mpimg.imread(image_paths[random_index])  # If not, just load image\n",
    "                steering = steering_ang[random_index]\n",
    "\n",
    "            im = speed_preprocess(im)  # Pass image through pipeline\n",
    "            batch_img.append(im)\n",
    "            batch_steering.append(steering)\n",
    "        yield (np.asarray(batch_img), np.asarray(batch_steering))  # Returns generator/ lazy iterator\n",
    "\n",
    "\n",
    "def nvidia_model():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(\n",
    "        Conv2D(24,\n",
    "               kernel_size=(5, 5),\n",
    "               strides=(2, 2),\n",
    "               input_shape=(66, 200, 3),\n",
    "               activation='elu'))\n",
    "    model.add(Conv2D(36, kernel_size=(5, 5), strides=(2, 2), activation='elu'))\n",
    "    model.add(Conv2D(48, kernel_size=(5, 5), strides=(2, 2), activation='elu'))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='elu'))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='elu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='elu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(50, activation='elu'))\n",
    "    model.add(Dense(10, activation='elu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    optimizer = Adam(learning_rate=1e-4)\n",
    "    # model.compile(loss='mse', optimizer=optimizer)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"cardata\"  # Define car data diretory\n",
    "columns = [\"image_id\", \"angle\", \"speed\"]\n",
    "\n",
    "# Read training data in from CSV\n",
    "data = pd.read_csv(os.path.join(datadir, \"training_norm3.csv\"))\n",
    "\n",
    "# Load angle/steering data\n",
    "image_paths, angles = load_img_steering(\n",
    "    datadir + \"/training_data/training_data\", data)\n",
    "\n",
    "# Generate training/test split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(image_paths,\n",
    "                                                      angles,\n",
    "                                                      test_size=0.2,\n",
    "                                                      random_state=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncol = 4\n",
    "nrow = 10\n",
    "\n",
    "fig, axs = plt.subplots(nrow, ncol, figsize=(15, 50))\n",
    "fig.tight_layout()\n",
    "\n",
    "for i in range(10):\n",
    "  randnum = random.randint(0, len(image_paths) - 1)\n",
    "  random_image = image_paths[randnum]\n",
    "  random_steering = angles[randnum]\n",
    "\n",
    "  original_image = mpimg.imread(random_image)\n",
    "  augmented_image, steering = random_augment(random_image, random_steering)\n",
    "  angle_image = angle_preprocess(augmented_image)\n",
    "  speed_image = speed_preprocess(augmented_image)\n",
    "\n",
    "  axs[i][0].imshow(original_image)\n",
    "  axs[i][0].set_title(\"Original Image\")\n",
    "\n",
    "  axs[i][1].imshow(augmented_image)\n",
    "  axs[i][1].set_title(\"Augmented Image\")\n",
    "\n",
    "  axs[i][2].imshow(angle_image)\n",
    "  axs[i][2].set_title(\"Angle Filter\")\n",
    "\n",
    "  axs[i][3].imshow(speed_image)\n",
    "  axs[i][3].set_title(\"Speed Filter\")\n",
    "  print(speed_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 10:33:25.590230: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - ETA: 0s - loss: 0.3072"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 10:34:53.603062: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 128s 427ms/step - loss: 0.3072 - val_loss: 0.0428\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 128s 426ms/step - loss: 0.0377 - val_loss: 0.0250\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 127s 424ms/step - loss: 0.0237 - val_loss: 0.0188\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 126s 422ms/step - loss: 0.0192 - val_loss: 0.0155\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 127s 423ms/step - loss: 0.0170 - val_loss: 0.0139\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 126s 420ms/step - loss: 0.0153 - val_loss: 0.0126\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 127s 423ms/step - loss: 0.0134 - val_loss: 0.0118\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 126s 421ms/step - loss: 0.0132 - val_loss: 0.0111\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 152s 509ms/step - loss: 0.0130 - val_loss: 0.0110\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 128s 427ms/step - loss: 0.0118 - val_loss: 0.0107\n"
     ]
    }
   ],
   "source": [
    "# TRAIN ANGLE MODEL\n",
    "angle_model = nvidia_model()\n",
    "batch_size = 64\n",
    "steps_per_epoch = X_train.size/batch_size\n",
    "angle_history = angle_model.fit(angle_batch_generator(X_train, y_train, batch_size,\n",
    "                                                      1),\n",
    "                                steps_per_epoch=300,\n",
    "                                epochs=10,\n",
    "                                validation_data=angle_batch_generator(\n",
    "                                    X_valid, y_valid, batch_size, 0),\n",
    "                                validation_steps=200,\n",
    "                                verbose=1,\n",
    "                                shuffle=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 10:55:02.476209: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011902423849727225\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from keras.models import load_model\n",
    "# ANGLE PREDICTIONS BASED ON VALIDATION DATA\n",
    "\n",
    "x_validTest, y_validTest = next(\n",
    "    angle_batch_generator(X_valid, y_valid, 1000, 0))\n",
    "Y_pred = angle_model.predict(x_validTest)\n",
    "MSE_angle = mean_squared_error(y_validTest, Y_pred)\n",
    "print(MSE_angle)\n",
    "\n",
    "angle_model_name = \"angle_model_\" + \"{0:.5f}\".format(MSE_angle) + \".h5\"\n",
    "angle_models_path = os.path.join(\"models\", angle_model_name)\n",
    "angle_model.save(angle_models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(angle_history.history['loss'])\n",
    "plt.plot(angle_history.history['val_loss'])\n",
    "plt.legend(['training', 'validation'])\n",
    "plt.title('Loss for Angle')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig(os.path.join(\"figures\",\"angle_loss_\" + \"{0:.5f}\".format(MSE_angle) + \".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cardata/training_data/training_data/1.png'\n",
      " 'cardata/training_data/training_data/2.png'\n",
      " 'cardata/training_data/training_data/3.png' ...\n",
      " 'cardata/training_data/training_data/13796.png'\n",
      " 'cardata/training_data/training_data/13797.png'\n",
      " 'cardata/training_data/training_data/13798.png']\n"
     ]
    }
   ],
   "source": [
    "# Load angle/steering data\n",
    "image_paths, speed = load_speed_img(datadir + \"/training_data/training_data\",\n",
    "                                     data)\n",
    "\n",
    "# Generate training/test split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(image_paths,\n",
    "                                                      speed,\n",
    "                                                      test_size=0.2,\n",
    "                                                      random_state=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  image_id   angle speed\n",
      "0    1.png  0.4375     0\n",
      "1    2.png  0.8125     1\n",
      "2    3.png  0.4375     1\n",
      "3    4.png  0.6250     1\n",
      "4    5.png  0.5000     0\n",
      "Found 8828 validated image filenames belonging to 2 classes.\n",
      "Found 551 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomaldridge/miniforge3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-29 23:33:33.923032: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - ETA: 0s - loss: 0.2093 - accuracy: 0.9171"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-29 23:35:10.641784: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 103s 798ms/step - loss: 0.2093 - accuracy: 0.9171 - val_loss: 0.5998 - val_accuracy: 0.8254\n",
      "Epoch 2/10\n",
      "122/122 [==============================] - 93s 754ms/step - loss: 0.0914 - accuracy: 0.9643 - val_loss: 0.4712 - val_accuracy: 0.8571\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - 94s 770ms/step - loss: 0.0737 - accuracy: 0.9717 - val_loss: 0.5139 - val_accuracy: 0.8591\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - 90s 731ms/step - loss: 0.0571 - accuracy: 0.9786 - val_loss: 0.4764 - val_accuracy: 0.8849\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - 91s 744ms/step - loss: 0.0525 - accuracy: 0.9808 - val_loss: 0.3728 - val_accuracy: 0.9008\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - 90s 735ms/step - loss: 0.0481 - accuracy: 0.9816 - val_loss: 0.2107 - val_accuracy: 0.9345\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - 94s 764ms/step - loss: 0.0443 - accuracy: 0.9838 - val_loss: 0.1514 - val_accuracy: 0.9444\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - 100s 816ms/step - loss: 0.0394 - accuracy: 0.9849 - val_loss: 0.1239 - val_accuracy: 0.9563\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - 95s 771ms/step - loss: 0.0349 - accuracy: 0.9861 - val_loss: 0.1076 - val_accuracy: 0.9722\n",
      "Epoch 10/10\n",
      " 35/122 [=======>......................] - ETA: 1:03 - loss: 0.0323 - accuracy: 0.9885"
     ]
    }
   ],
   "source": [
    "# TRANSFER LEARNING ATTEMPT\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "base_model = MobileNetV2(\n",
    "    weights='imagenet', include_top=False\n",
    ")  #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "preds = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=base_model.input, outputs=preds)\n",
    "\n",
    "for layer in model.layers[:20]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[20:]:\n",
    "    layer.trainable=True\n",
    "\n",
    "model.compile(optimizer=SGD(learning_rate = 0.01),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# datagen = ImageDataGenerator(featurewise_center=True,\n",
    "#                              featurewise_std_normalization=True,\n",
    "#                              rotation_range=20,\n",
    "#                              width_shift_range=0.2,\n",
    "#                              height_shift_range=0.2,\n",
    "#                              horizontal_flip=True,\n",
    "#                              validation_split=0.2)\n",
    "\n",
    "# tg = datagen.flow(np.asarray(X_train), y_train, 32, 1, subset='training')\n",
    "# vg = datagen.flow(np.asarray(X_valid), y_valid, 32, 1, subset='validation')\n",
    "\n",
    "# test = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "# print(X_train)\n",
    "# test_gen = test.flow_from_directory(X_train,\n",
    "#                                     y_train,\n",
    "#                                     batch_size=32,\n",
    "#                                     color_mode='rgb')\n",
    "# valid_gen = test.flow(np.asarray(X_valid), y_valid, 32, 0)\n",
    "\n",
    "data = pd.read_csv(\"cardata/training_norm3.csv\")\n",
    "data['speed'] = data['speed'].astype(str)\n",
    "print(data.head())\n",
    "\n",
    "train_df, validate_df = train_test_split(data, test_size=0.20, random_state=42)\n",
    "# train_df = train_df.reset_index(drop=True)\n",
    "# validate_df = validate_df.reset_index(drop=True)\n",
    "batch_size = 72\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df, \n",
    "    \"cardata/training_data/training_data/\", \n",
    "    x_col='image_id',\n",
    "    y_col='speed',\n",
    "    target_size=(320,240),\n",
    "    class_mode='binary',\n",
    "    batch_size=batch_size,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "valid_generator = train_datagen.flow_from_dataframe(\n",
    "    validate_df, \n",
    "    \"cardata/training_data/training_data/\", \n",
    "    x_col='image_id',\n",
    "    y_col='speed',\n",
    "    target_size=(320,240),\n",
    "    class_mode='binary',\n",
    "    batch_size=batch_size,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "\n",
    "speed_history = model.fit_generator(generator=train_generator,\n",
    "                                    steps_per_epoch=train_generator.samples // batch_size,\n",
    "                                    epochs=10,\n",
    "                                    validation_data=valid_generator,\n",
    "                                    validation_steps=valid_generator.samples // batch_size)\n",
    "\n",
    "x_validTest, y_validTest = next(\n",
    "    speed_batch_generator(X_valid, y_valid, 1000, 0))\n",
    "Y_pred = model.predict(x_validTest)\n",
    "bce = BinaryCrossentropy()\n",
    "print(str(bce(y_validTest, Y_pred).numpy()))\n",
    "speed_model_name = \"speed_model_\" + \"{0:.5f}\".str(bce(y_validTest, Y_pred).numpy()) + \".h5\"\n",
    "speed_models_path = os.path.join(\"models\", speed_model_name)\n",
    "model.save(speed_models_path)\n",
    "\n",
    "plt.plot(speed_history.history['loss'])\n",
    "plt.plot(speed_history.history['val_loss'])\n",
    "plt.legend(['training', 'validation'])\n",
    "plt.title('Loss for Speed')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig(os.path.join(\"figures\",\"speed_loss_\" + \"{0:.5f}\".str(bce(y_validTest, Y_pred).numpy()) + \".png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9253128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomaldridge/miniforge3/envs/tf/lib/python3.9/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "bce = BinaryCrossentropy()\n",
    "print(bce(y_validTest, Y_pred).numpy())\n",
    "model.save(\"models/speed_model_\" +str(bce(y_validTest, Y_pred).numpy())+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 13:56:26.759950: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - ETA: 0s - loss: 0.6838"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 14:02:30.791231: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 464s 2s/step - loss: 0.6838 - val_loss: 0.6634\n",
      "Epoch 2/12\n",
      " 46/300 [===>..........................] - ETA: 5:04 - loss: 0.6532"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bn/qfvxtgcj39z5kcs_86kg57mr0000gn/T/ipykernel_59501/1140259546.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                         restore_best_weights = True)\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m speed_history = speed_model.fit(speed_batch_generator(X_train, y_train, batch_size,\n\u001b[0m\u001b[1;32m     13\u001b[0m                                                       1),\n\u001b[1;32m     14\u001b[0m                                 \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# TRAIN SPEED MODEL\n",
    "speed_model = nvidia_model()\n",
    "batch_size = 174\n",
    "steps_per_epoch = X_train.size/batch_size\n",
    "\n",
    "\n",
    "from keras import callbacks\n",
    "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\", \n",
    "                                        mode =\"min\", patience = 5, \n",
    "                                        restore_best_weights = True)\n",
    "\n",
    "speed_history = speed_model.fit(speed_batch_generator(X_train, y_train, batch_size,\n",
    "                                                      1),\n",
    "                                steps_per_epoch=300,\n",
    "                                epochs=12,\n",
    "                                validation_data=speed_batch_generator(\n",
    "                                    X_valid, y_valid, batch_size, 0),\n",
    "                                validation_steps=200,\n",
    "                                callbacks=earlystopping,\n",
    "                                verbose=1,\n",
    "                                shuffle=1)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# ANGLE PREDICTIONS BASED ON VALIDATION DATA\n",
    "\n",
    "x_validTest, y_validTest = next(\n",
    "    speed_batch_generator(X_valid, y_valid, 1000, 0))\n",
    "Y_pred = speed_model.predict(x_validTest)\n",
    "MSE_speed = mean_squared_error(y_validTest, Y_pred)\n",
    "print(MSE_speed)\n",
    "\n",
    "speed_model_name = \"speed_model_\" + \"{0:.5f}\".format(MSE_speed) + \".h5\"\n",
    "speed_models_path = os.path.join(\"models\", speed_model_name)\n",
    "speed_model.save(speed_models_path)\n",
    "\n",
    "plt.plot(speed_history.history['loss'])\n",
    "plt.plot(speed_history.history['val_loss'])\n",
    "plt.legend(['training', 'validation'])\n",
    "plt.title('Loss for Speed')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig(os.path.join(\"figures\",\"speed_loss_\" + \"{0:.5f}\".format(MSE_speed) + \".png\"))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dbf4ff8a4851cdef5ad310b0693d3c5f1975d91208526f0ee562ffca9cac19bd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
